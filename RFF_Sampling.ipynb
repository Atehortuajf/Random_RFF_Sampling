{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9niyNfo4RL3X",
        "1fODd6tcRbb2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TODO\n",
        "- Understand why training overfits initial RFFs\n",
        "- Check numerical gradients and analytical gradients are equal\n",
        "- Host and download the domain being trained on.\n",
        "- Prepare datasets of dim > 2 (i.e. not images)\n",
        "- Generalize code to dim > 2"
      ],
      "metadata": {
        "id": "ZsNB3TFP644c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dependencies and Imports"
      ],
      "metadata": {
        "id": "mXoJDmowRA-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HwhFIFMQ_9f",
        "outputId": "2162379d-a93b-4c27-8a23-bc76322b1461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataset import TensorDataset\n",
        "from torch import nn, optim\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#device = \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raK1CnJ9RG7g",
        "outputId": "3302bf3d-e78c-465e-fe87-218f807e5fef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Global Parameters"
      ],
      "metadata": {
        "id": "AjQCrEKoVOdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = 1. # Feature sampling sd\n",
        "feature_num = 3 # Starting number of features\n",
        "sample_size = 1000 # How many random feature samples when finding new feature\n",
        "learning_rate = 1e-3\n",
        "model_size = 64\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "ACZXyuvOVRAR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Preparation"
      ],
      "metadata": {
        "id": "9niyNfo4RL3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make dataset, taken from https://github.com/jmclong/random-fourier-features-pytorch\n",
        "image = torchvision.io.read_image('circle.jpg').float()\n",
        "_, H, W = image.shape\n",
        "def linspace_func(nx): return torch.linspace(0.0, 1.0, nx)\n",
        "linspaces = map(linspace_func, (H, W))\n",
        "coordinates = torch.meshgrid(*linspaces, indexing='ij')\n",
        "rect_coords = torch.stack(coordinates, dim=-1)\n",
        "image = image.permute((1, 2, 0))\n",
        "image /= 255.0\n",
        "coords = rect_coords.flatten(0, -2)\n",
        "image = image.flatten(0, -2)\n",
        "dataset = TensorDataset(coords, image)\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "train_indices = indices\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "\n",
        "train_dataloader = DataLoader(dataset, batch_size=1024, sampler=train_sampler)\n",
        "expand_dataloader = DataLoader(dataset, batch_size=1024, sampler=train_sampler)"
      ],
      "metadata": {
        "id": "yoednK_ERQlF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MLP Data Structures"
      ],
      "metadata": {
        "id": "1fODd6tcRbb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fourier transform receive layer\n",
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, feature_num, size):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers = nn.Sequential(nn.Linear(feature_num,size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "    \n",
        "# Fourier Space MLP fit\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def  __init__(self, size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.size = size\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers = nn.Sequential(\n",
        "            #nn.Linear(10, 16),\n",
        "            #SineLayer(),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(size, size),\n",
        "            #SineLayer(),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(size, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Gaussian Encoding Layer\n",
        "class GaussianEncoding(nn.Module):\n",
        "  def __init__(self, sigma, input_size, feature_num):\n",
        "    super(GaussianEncoding, self).__init__()\n",
        "    self.b = torch.randn((feature_num, input_size)) * sigma\n",
        "    self.b = self.b.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.sin(2 * np.pi * x @ self.b.T)\n",
        "\n",
        "# Sine Layer\n",
        "class SineLayer(nn.Module):  \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return torch.sin(input)"
      ],
      "metadata": {
        "id": "TZ26pNkeRleV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Expansion"
      ],
      "metadata": {
        "id": "g8tzWdU0Rvjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findFeature(encoding, transition_layer, model):\n",
        "  z = transition_layer(encoding(X))\n",
        "  preds = model(z)\n",
        "  gz = sum(preds)\n",
        "  #print(z.shape)\n",
        "  #print(gz.shape)\n",
        "  dgdz = torch.zeros([3,z.shape[0],z.shape[1]])\n",
        "  for i in range(3):\n",
        "    dgdz_coord = torch.autograd.grad(gz[i], z, retain_graph=True)\n",
        "    dgdz[i,:,:] = dgdz_coord[0]\n",
        "  #print('dgdz')\n",
        "  #print(dgdz.shape)\n",
        "  dgdz = dgdz.to(device)\n",
        "  best_dldw = 0\n",
        "  for i in range(sample_size):\n",
        "    a = torch.randn((1,2)).to(device)\n",
        "    ax = torch.matmul(a, torch.permute(X, (1,0)))\n",
        "    pred_minus_y = torch.add(preds,y,alpha=-1)\n",
        "    pred_minus_y = torch.reshape(pred_minus_y,(pred_minus_y.shape[0],pred_minus_y.shape[1],1))\n",
        "    pred_minus_y = torch.permute(pred_minus_y, (1,0,2))\n",
        "    #print('p - y')\n",
        "    #print(pred_minus_y.shape)\n",
        "    two_terms = torch.mul(pred_minus_y, dgdz)\n",
        "    #print('ax')\n",
        "    #print(ax.shape)\n",
        "    #print (two_terms.shape)\n",
        "    dLdw = torch.mul(torch.permute(two_terms,(0,2,1)), torch.sin(ax))\n",
        "    #print('dLdw')\n",
        "    #print(dLdw.shape)\n",
        "    dLdw = torch.sum(dLdw, dim=(0,2))\n",
        "    #print('dLdw summed over dimensions')\n",
        "    #print(dLdw)\n",
        "    norm = torch.linalg.vector_norm(dLdw)\n",
        "    #print('norm')\n",
        "    #print(norm)\n",
        "    if norm > best_dldw:\n",
        "      best_dldw = norm\n",
        "      best_a = a\n",
        "  best_feature = makeFeatureEncoding(encoding, best_a, feature_num)\n",
        "  '''best_feature = GaussianEncoding(sigma, 2, feature_num).to(device)\n",
        "  encoding_sd = encoding.state_dict()\n",
        "  best_feature.load_state_dict(encoding_sd, strict=False)\n",
        "  best_feature.b = torch.nn.Parameter(F.pad(input=encoding.b, pad=(0,0,0,1), mode='constant', value=0))\n",
        "  best_feature.b.data[-1] = best_a'''\n",
        "  print(\"New feature with dldw \" + str(best_dldw.item()))\n",
        "  return best_feature, best_dldw\n",
        "\n",
        "def randFeature(encoding):\n",
        "  rand_feature = GaussianEncoding(sigma, 2, feature_num).to(device)\n",
        "  encoding_sd = encoding.state_dict()\n",
        "  rand_feature.load_state_dict(encoding_sd, strict=False)\n",
        "  rand_feature.b = torch.nn.Parameter(F.pad(input=encoding.b, pad=(0,0,0,1), mode='constant', value=0))\n",
        "  rand_feature.b.data[-1] = torch.randn((1,2)).to(device)\n",
        "  \n",
        "def makeFeatureEncoding(encoding, feature, feature_num):\n",
        "  encoding_sd = encoding.state_dict()\n",
        "  new_feature = GaussianEncoding(sigma, 2, feature_num).to(device)\n",
        "  new_feature.load_state_dict(encoding_sd, strict=False)\n",
        "  new_feature.b = torch.nn.Parameter(F.pad(input=encoding.b, pad=(0,0,0,1), mode='constant', value=0))\n",
        "  new_feature.b.data[-1] = feature\n",
        "  return new_feature"
      ],
      "metadata": {
        "id": "2OkfdT7IScot"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expandTransition(transition_layer):\n",
        "  transition_sd = transition_layer.state_dict()\n",
        "  expanded_transition = TransitionLayer(feature_num, model_size).to(device)\n",
        "  expanded_transition.load_state_dict(transition_sd, strict=False)\n",
        "  trans_weights = transition_layer.layers[0].weight\n",
        "  pad_weights = torch.nn.Parameter(F.pad(input=trans_weights, pad=(0,1,0,0), mode='constant', value=0))\n",
        "  #pad_weights.data[:,-1] = torch.randn(pad_weights[:,-1].shape)\n",
        "  expanded_transition.layers[0].weight = pad_weights\n",
        "  return expanded_transition\n",
        "\n",
        "def expandModel(model):\n",
        "  #return model\n",
        "  model_sd = model.state_dict()\n",
        "  expanded_model = NeuralNetwork(model_size).to(device)\n",
        "  expanded_model.load_state_dict(model_sd, strict = False)\n",
        "  for layer in expanded_model.layers:\n",
        "    if isinstance(layer, nn.Linear) and layer != expanded_model.layers[-1]:\n",
        "      new_weights = torch.nn.Parameter(F.pad(input=layer.weight, pad=(0,1,0,1), mode='constant', value=0))\n",
        "      layer.weight = new_weights\n",
        "  return expanded_model"
      ],
      "metadata": {
        "id": "nSoxArW_W2uU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expandFeatures(feature_num, model_size, model, transition_layer, encoding):\n",
        "  expanded_transition = expandTransition(transition_layer)\n",
        "  #expanded_model = expandModel(model)\n",
        "  best_feature, best_dldw = findFeature(encoding, transition_layer, model)\n",
        "  # best_feature = randFeature(encoding)\n",
        "  numerical_grad = checkGrad(best_feature.b.data[-1], encoding, expanded_transition, model, 1, feature_num)\n",
        "  print(\"Numerical gradient: \" + str(numerical_grad.item()))\n",
        "  feature_num += 1\n",
        "  #model_size += 1\n",
        "  return best_feature, expanded_transition, model, best_dldw\n",
        "\n",
        "def checkGrad(feature, encoding, transition_layer, model, epsilon, feature_num):\n",
        "  plus_eps_ft = makeFeatureEncoding(encoding, torch.add(feature, epsilon), feature_num)\n",
        "  minus_eps_ft = makeFeatureEncoding(encoding, torch.add(feature, -1*epsilon), feature_num)\n",
        "  plus_eps = model(transition_layer(plus_eps_ft(X)))\n",
        "  minus_eps = model(transition_layer(minus_eps_ft(X)))\n",
        "  numerical_grad = torch.mul(torch.sub(plus_eps,minus_eps), 1./(2*epsilon))\n",
        "  breakpoint()\n",
        "  return torch.linalg.vector_norm(torch.sum(numerical_grad, dim = 0))"
      ],
      "metadata": {
        "id": "vz6kEGT4R9fa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "HZKeIHA-ct4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkStall(losses):\n",
        "    n = 100\n",
        "    iter = len(losses) - 1\n",
        "    if iter < n: return False\n",
        "    time = np.array([i for i in range(n)])\n",
        "    loss_array = np.array(losses[-(n+1):-1])\n",
        "    p = np.polyfit(time, loss_array, 1)\n",
        "    return p[0] > -1e-5 # Tweak this"
      ],
      "metadata": {
        "id": "yexoK5AOc52b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b, (X, y) = next(enumerate(train_dataloader))"
      ],
      "metadata": {
        "id": "-d79VvzncvVf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training code\n",
        "transition_layer = TransitionLayer(feature_num, model_size)\n",
        "transition_layer = transition_layer.to(device)\n",
        "model = NeuralNetwork(model_size)\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "params = chain(transition_layer.parameters(), model.parameters())\n",
        "optimizer = optim.SGD(params, lr=learning_rate) \n",
        "encoding = GaussianEncoding(1., 2, feature_num).to(device)\n",
        "epochs = 5\n",
        "\n",
        "losses = []\n",
        "slopes = []\n",
        "dldws = {}\n",
        "stalls = [0]\n",
        "batch_losses = []\n",
        "#b, (X, y) = next(enumerate(train_dataloader))\n",
        "\n",
        "for i in range(10000):\n",
        "  #for batch_index, (X, y) in enumerate(train_dataloader):\n",
        "  X = X.to(device)\n",
        "  y = y.to(device)\n",
        "  Xp = encoding(X)\n",
        "  pred = model(transition_layer(Xp))\n",
        "  loss = loss_fn(pred, y)\n",
        "  losses.append(loss.item())\n",
        "  if (i > 2):\n",
        "    slopes.append((losses[-1] - losses[-2])/learning_rate)\n",
        "  if (len(losses) + 1) % 1000 == 0:\n",
        "    print(\"loss: \" + str(np.mean(losses[-1:-101:-1])) + \"\\nslope: \" + str(slopes[-1]))\n",
        "  #if False:\n",
        "  if(((len(losses) - stalls[-1]) > 100  and checkStall(losses)) and feature_num < 10):\n",
        "    stalls.append(len(losses))\n",
        "    encoding, transition_layer, model, dldw = expandFeatures(feature_num, model_size, model, transition_layer, encoding)\n",
        "    params = chain(transition_layer.parameters(), model.parameters())\n",
        "    optimizer = optim.SGD(params, lr=learning_rate)\n",
        "    feature_num += 1\n",
        "    dldws[len(losses)] = dldw\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "with torch.no_grad():\n",
        "    feature_coords = encoding(rect_coords.to(device))\n",
        "    image = model(transition_layer(feature_coords))\n",
        "    plt.imshow(image.cpu().numpy())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tUGbwACtcybe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "b8c9e3b1-7d21-498c-dd16-3f839c50374a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.054886562563478944\n",
            "slope: -0.010855495929718018\n",
            "New feature with dldw 21.634742736816406\n",
            "> <ipython-input-28-a43067169ae3>(19)checkGrad()\n",
            "-> return torch.linalg.vector_norm(torch.sum(numerical_grad, dim = 0))\n",
            "(Pdb) numerical_grad\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], device='cuda:0', grad_fn=<MulBackward0>)\n",
            "--KeyboardInterrupt--\n",
            "(Pdb) q\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BdbQuit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-40113865d495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m  \u001b[0;32mand\u001b[0m \u001b[0mcheckStall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeature_num\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mstalls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdldw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpandFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-a43067169ae3>\u001b[0m in \u001b[0;36mexpandFeatures\u001b[0;34m(feature_num, model_size, model, transition_layer, encoding)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mbest_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_dldw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# best_feature = randFeature(encoding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mnumerical_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_transition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Numerical gradient: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumerical_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mfeature_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-a43067169ae3>\u001b[0m in \u001b[0;36mcheckGrad\u001b[0;34m(feature, encoding, transition_layer, model, epsilon, feature_num)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mnumerical_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplus_eps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminus_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumerical_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-a43067169ae3>\u001b[0m in \u001b[0;36mcheckGrad\u001b[0;34m(feature, encoding, transition_layer, model, epsilon, feature_num)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mnumerical_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplus_eps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminus_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumerical_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.9/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local Variables"
      ],
      "metadata": {
        "id": "xnuBGSoecWEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gradients_num = [0] + [(losses[i+1] - losses[i-1])/(2*learning_rate) for i in range(1,len(losses)-1)] + [0]\n",
        "for stall in stalls:\n",
        "  if stall == 0: continue\n",
        "  print(\"At iter \" + str(stall))\n",
        "  print(\"Numerical Gradient: \" + str(gradients_num[stall]))\n",
        "  print(\"Analytical Gradient: \" + str(dldws[stall].item()) + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufPagvCNnipr",
        "outputId": "d6c4b4a5-eaa5-42d1-e1e3-2adc30495299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At iter 1035\n",
            "Numerical Gradient: -0.008530914783477783\n",
            "Analytical Gradient: 36.35417938232422\n",
            "\n",
            "At iter 1136\n",
            "Numerical Gradient: -0.006843358278274536\n",
            "Analytical Gradient: 39.96036911010742\n",
            "\n",
            "At iter 1237\n",
            "Numerical Gradient: -0.005587935447692871\n",
            "Analytical Gradient: 30.55134391784668\n",
            "\n",
            "At iter 1338\n",
            "Numerical Gradient: -0.004604458808898926\n",
            "Analytical Gradient: 34.71858215332031\n",
            "\n",
            "At iter 1439\n",
            "Numerical Gradient: -0.0038258731365203857\n",
            "Analytical Gradient: 40.54592514038086\n",
            "\n",
            "At iter 1540\n",
            "Numerical Gradient: -0.003207474946975708\n",
            "Analytical Gradient: 34.62732696533203\n",
            "\n",
            "At iter 1641\n",
            "Numerical Gradient: -0.002730637788772583\n",
            "Analytical Gradient: 33.418800354003906\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check weights\n",
        "weights = transition_layer.layers[0].weight\n",
        "torch.linalg.norm(weights, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EZbrCV9clgh",
        "outputId": "a8c1901f-c870-45b1-898c-504f94866243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.5441, 2.7865, 2.4804, 0.0197, 0.0390, 0.0114, 0.0176, 0.0295, 0.0269,\n",
              "        0.0327], device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf-yMUMzyBMC",
        "outputId": "22046eed-95e0-44a8-f68b-1f54e87ea31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=64, out_features=64, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize loss over iteration and stalls\n",
        "plt.plot(losses)\n",
        "plt.plot(slopes)\n",
        "for stall in stalls:\n",
        "  plt.axvline(x=stall, color = 'k')\n",
        "plt.axis([0,10000,-0.1,0.2])\n",
        "plt.show()\n",
        "print(stalls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "3LKY7kxichI-",
        "outputId": "4e9b8d18-5269-4e49-c503-14d39f9346be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD8CAYAAABdCyJkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc7UlEQVR4nO3de5Qc5Xnn8e/T3XPRMIM0QuJiSQYRBGtszkEgY1hviGxugjjIOcExLInlBEeJNzjeeJ2NWGwcy/EurHOcxGtiUIyyxCc2JuDEChaRhUC2lwTQcLFAwKCRADFjIaH7ldHM9LN/1NuamqZHmpmqnp7u/n3O6dNV7/tW1TNFid9UVXeNuTsiIiJjlal0ASIiUt0UJCIikoiCREREElGQiIhIIgoSERFJREEiIiKJpBIkZrbAzDrNrMvMlpTo/5yZvWhm681sjZmdHutbZGYbw2tRGvWIiMj4saTfIzGzLPAKcAXQDawDbnD3F2NjPgQ86e6HzOzTwHx3/7iZTQU6gHmAA08DF7r77kRFiYjIuEnjjOQioMvdN7v7EeA+YGF8gLs/5u6HwuwTwMwwfRWw2t13hfBYDSxIoSYRERknuRTWMQN4IzbfDXzgGONvAh4+xrIzSi1kZouBxQCZTObCuXPnDrsBB17o2cspbc2cfGLT8eo/rs7OTgDOOeecIdPH6hvpOBGR8fL000/vcPfpaa83jSAZMTP7LaLLWL8y2mXdfRmwDKCtrc07OjqOOf7sLzzM73zwDG65+j1jKXWI+fPnA7B27doh08fqG+k4EZHxYmavl2O9aVza6gFmxeZnhrYhzOxy4FbgWnfvHc2yY3FCY5ZDvQNprEpERI4hjSBZB8wxs9lm1ghcD6yIDzCzucDdRCGyPda1CrjSzNrNrB24MrQl1tKY4+CR/jRWJSIix5D40pa795vZzUQBkAWWu/sGM1sKdLj7CuBrQCvwj2YGsMXdr3X3XWb2FaIwAljq7ruS1gTQ0pjl8BGdkYiIlFsq90jcfSWwsqjtttj05cdYdjmwPI064lqachxUkIiIlF3NfrM9ukeiS1siIuVWs0HS0pjVGYmIyDio4SDJcVg320VEyq5mg+SEJp2RiIiMh5oNkpbGnO6RiIiMg5oNkhMasxzqGyCfT/ZQShERObaaDZLW5hzu6EuJIiJlVrNB0tbcAMABXd4SESmrmg2S1qbou5b731aQiIiUU80GSVtzIUj6KlyJiEhtq+EgiS5t7dMZiYhIWdVskJzYrEtbIiLjoWaDpHBGoktbIiLlVcNBEp2RHNAZiYhIWdVskLQ0ZsmYLm2JiJRbzQaJmdHalNOlLRGRMqvZIIHoPonOSEREyqvGgySnj/+KiJRZTQfJic0NHOjVpS0RkXKq6SBpa87p0paISJkpSEREJJEaD5IGfWpLRKTMajpIWsMZibv+uJWISLnUdJBMntRAf945pL/dLiJSNjUdJO0t0fO2dh86UuFKRERqV00HyZSWRgD2HNJ9EhGRcqnpIGkPQaIzEhGR8kklSMxsgZl1mlmXmS0p0X+pmT1jZv1mdl1R34CZPRdeK9Kop2Dw0pbOSEREyiWXdAVmlgXuBK4AuoF1ZrbC3V+MDdsCfBL4fIlVHHb385PWUcrkECR7dUYiIlI2iYMEuAjocvfNAGZ2H7AQOBok7v5a6MunsL0RmzKpcGlLZyQiIuWSxqWtGcAbsfnu0DZSzWbWYWZPmNlHU6jnqMZchtamnO6RiIiUURpnJEmd7u49ZnYm8KiZPe/um4oHmdliYDFAU1PTiFc+paVBn9oSESmjNM5IeoBZsfmZoW1E3L0nvG8G1gJzhxm3zN3nufu8hoaGERfX3tKoMxIRkTJKI0jWAXPMbLaZNQLXAyP69JWZtZtZU5ieBnyQ2L2VNExpadA9EhGRMkocJO7eD9wMrAJeAu539w1mttTMrgUws/ebWTfwMeBuM9sQFn8P0GFmPwceA24v+rRXYlNaGvWpLRGRMkrlHom7rwRWFrXdFpteR3TJq3i5fwPOS6OG4bTrjEREpKxq+pvtEN0j2Xu4j/6Bcf3ksYhI3aj5IJnWFn3Ca9dBXd4SESmHmg+S6a1RkGzf31vhSkREalPtB0k4I3nrgIJERKQcaj5ITi4Eic5IRETKouaDZFqrgkREpJxqPkgmNWZpa8opSEREyqTmgwSi+yS6RyIiUh51ESTT2pp0RiIiUiZ1ESTT25rYoSARESmL+giS1iZ9j0REpEzqIkhOndzMgd5+9r+tZ26JiKStLoJkxpRJAPTsOVzhSkREak99BEl7CJLdChIRkbTVRZDM1BmJiEjZ1EWQTGttojGbUZCIiJRBXQRJJmOcNqVZl7ZERMqgLoIEohvuOiMREUlffQWJzkhERFJXN0Fy+kktbN/fy8He/kqXIiJSU+omSH5peisAr+44WOFKRERqS90EyZkhSDa9daDClYiI1Ja6CZLTT2ohY7DpLZ2RiIikqW6CpLkhy6ypLTojERFJWd0ECUT3STbrjEREJFV1FSRzTm5l01sH6BvIV7oUEZGaUVdB8t4ZkznSn+eVbfsrXYqISM2oqyA5b8ZkAJ7v3lvhSkREakcqQWJmC8ys08y6zGxJif5LzewZM+s3s+uK+haZ2cbwWpRGPcM5fWoLbc05nu9RkIiIpCVxkJhZFrgTuBo4F7jBzM4tGrYF+CTw3aJlpwJfAj4AXAR8yczak9Y0nEzGeN+7JrNeZyQiIqlJ44zkIqDL3Te7+xHgPmBhfIC7v+bu64Hiu9xXAavdfZe77wZWAwtSqGlYc989hZe27uOAHpUiIpKKNIJkBvBGbL47tKW6rJktNrMOM+vo6xv7317/j780jf68s+7VXWNeh4iIDKqam+3uvszd57n7vIaGhjGvZ94Z7TRmMzzetSPF6kRE6lcaQdIDzIrNzwxt5V52TJobslx4ejs/26ggERFJQxpBsg6YY2azzawRuB5YMcJlVwFXmll7uMl+ZWgrqyvOPYXObfvp2q7HpYiIJJU4SNy9H7iZKABeAu539w1mttTMrgUws/ebWTfwMeBuM9sQlt0FfIUojNYBS0NbWV1z3mmYwY/Wby33pkREal4ujZW4+0pgZVHbbbHpdUSXrUotuxxYnkYdI3Xq5Gbef8ZU/unZbj7z4bPIZGw8Ny8iUlOq5mZ72n7r4tN5bechHn15e6VLERGpanUbJFe/71ROm9zMt36yCXevdDkiIlWrboOkIZvhjy6bw9Ov7+ZfdK9ERGTM6jZIAH5z3izeN+NE/mzFBrbuPVzpckREqlJdB0k2Y/zVx+fS2zfAp+7tYPfBI5UuSUSk6tR1kACcdXIr37zxAjZuP8Bv3PVvvKAnA4uIjErdBwnAh845mb//3Ys48HY/C+98nM/d/xxPv76bfF434UVEjieV75HUgovPPIkf//Gl/J9Hu/iHJ1/nB8/0ML2tibmzptCz+zBNDRme3LyTt/sGyGaMI/15GnPKYRERBUnMlJZGvviRc/ns5XNY89I21na+xfruvbyx+xAAH1/2BG++sQeAs7/wMM0NGXpe303GjMu//hOe79lLxuCGZU/w8pv7yRj80feepSmX4dUdBzHgzx96kS27DpEx+MaajeSyRmM2Qy5jNOQyNGQyNOSMXCZDQzZDQ9ZoyGYGx8XaGsJyjbnoPZfNhDFGLmOY6YuWIlJ+CpISTmxu4NfnzuTX50Zfxr/0X6bS25/nL266iE8/0kp/3vnDK85m39t93P1PjXjeOeeUNjZkM+TdGcg7/QN58g7ru/fQ259n18EjuMP3ntrCm3vfJu/O11e/UtafI5sxspkoVAbfM4Pz2WHah/SXaI+Pzx5j/UP6R7b+TMbImh2tPZsxMoV5MzIZyGUyZDMcbS+8x5fPZAaXGVwPCleRMlCQjEDGjEkNWX55znSmtTYB8JnL5gCw+msnAHDnjRew4W/bALj/Dy5h/n3R34df+ycfAmD+qugPP65duoD5P70dgEe+ejX9eefIQJ7+AadvIB9eURAV2vvzeY70R++F/r7QN9yy/fkQaHlnIF80PzBMe3z8gNPbl6c/P1B6PQPHWH94TUQZ42j4HA2eePi8I8Ri47NDxxXec1krCrVCiGfIGkPWmykEnhUHJWF8NH38QLWjYVp4ZTNRUBYCd7C9MCaqy2zwZxs6Jtpupmgd0TJEbWHb8f0SX15BXZ8UJBWUy2bIZaNH29ca91IBFYXhO4Mo1p538oUw8sFQis70ODpdPC5fND6+TN7D9mLj8rG6CmeR+aPLw0A+z4Dzjm30DxkX1d3bH6+XIdvozw9ddz62XwbHcbT2amchnLIWwicWYoVwtEJwWlGoxUJsyLIZiwJ5mBAbEpBFAVhyTIkAHhKg8VpCiB79GWzoz2Ox9kLdmVgNhf6sDR2bCaEf36YN2Xbsl4IS6x1aS+jPlKix0B+WKxcFiZSFhd/Uc7WXkWXj7uSdoaEWD7BYWOZDQA64h9Dm6DLug8HkRwMs6h8yJmwnX7TdeADnw7KD2wnrKtQYH1PYnheNyQ/ddvHy76glP3R7A05s21F//0C+xHYGf5ah9THk5/ISdRfvBxkdBYnIBBH9Bhr95iyVNRhiUdAVwjnvjseCKe+8Izzdh/bHAzLvxf3x4Bv8ZSL+S8JgEMZ+2Sj0lVjvQHxs0S8Rv39HefaXgkREpMjRM+pKF5Ky3y/TevVFCBERSURBIiIiiShIREQkEQWJiIgkoiAREZFEFCQiIpKIgkRERBJRkIiISCIKEhERSURBIiIiiShIREQkEQWJiIgkkkqQmNkCM+s0sy4zW1Kiv8nMvh/6nzSzM0L7GWZ22MyeC6+70qhHRETGT+KHW5pZFrgTuALoBtaZ2Qp3fzE27CZgt7ufZWbXA3cAHw99m9z9/KR1iIhIZaRxRnIR0OXum939CHAfsLBozELg3jD9AHCZ6W9yiojUhDSCZAbwRmy+O7SVHOPu/cBe4KTQN9vMnjWzn5jZLw+3ETNbbGYdZtbR19eXQtkiIpKGSv/dlq3Au919p5ldCPyzmb3X3fcVD3T3ZcAygLa2Nv0tTBGRCSKNM5IeYFZsfmZoKznGzHLAZGCnu/e6+04Ad38a2AScnUJNIiIyTtIIknXAHDObbWaNwPXAiqIxK4BFYfo64FF3dzObHm7WY2ZnAnOAzSnUJCIi4yTxpS137zezm4FVQBZY7u4bzGwp0OHuK4B7gO+YWRewiyhsAC4FlppZH5AH/sDddyWtSURExk8q90jcfSWwsqjtttj028DHSiz3IPBgGjWIiEhl6JvtIiKSiIJEREQSUZCIiEgiChIREUlEQSIiIokoSEREJBEFiYiIJKIgERGRRBQkIiKSiIJEREQSUZCIiEgiChIREUlEQSIiIokoSEREJBEFiYiIJKIgERGRRBQkIiKSiIJEREQSUZCIiEgiChIREUlEQSIiIokoSEREJBEFiYiIJKIgERGRRBQkIiKSiIJEREQSUZCIiEgiqQSJmS0ws04z6zKzJSX6m8zs+6H/STM7I9Z3S2jvNLOr0qhHRETGT+IgMbMscCdwNXAucIOZnVs07CZgt7ufBfwlcEdY9lzgeuC9wALgb8L6RESkSuRSWMdFQJe7bwYws/uAhcCLsTELgT8L0w8A3zQzC+33uXsv8KqZdYX1/XsKdYkM5X7seY7Vn2TZpP3l3nY51z2Cn2vYeoZpr5rxw61mgtWTgjSCZAbwRmy+G/jAcGPcvd/M9gInhfYnipadUWojZrYYWAzQ1NSUQtkpcYeBXnj1p7DvF+AD8LOvw85N0LsPHl4C+T74xTOQaYAVn4FfPAv9b8ODvwf5fvB8tFw+H6bDvMfm39Hn0TQeDpzwHp8mjBnSP4JlCj/XO/6hJ+0rHpfGOkv1xfpFpOzSCJJx4e7LgGUAbW1tlfu/hDu8vRfW3g4bV8Prj0ft9/4a7DoYTa/5MuwP0x33QEMLHDkUzb/yYzgS+rqfgkwOLDP4XvzKZIumG8K8Re9YNI0Nthfa4tOl+odtK/ywhbYwDUPnU+8jhXUW98fbi7YVHzvi/iTLJugv57rf0X+8ZYtXlca2h9nGsNuut/HDrWaU6//yb4xu/SOURpD0ALNi8zNDW6kx3WaWAyYDO0e47MTx2v+Dng7o742CZMaFMHkWNDTDJ+6CH38+CoT/sQbWXhMt88W10fu/zo/eP78WHgrTn107ruWLiJRDGp/aWgfMMbPZZtZIdPN8RdGYFcCiMH0d8Ki7e2i/PnyqazYwB3gqhZrS5R5dqvq/vxpdiprybviTTfB7a6D9dGg9Bc78FWg8AXJN0NhS6YpFRMZN4jOScM/jZmAVkAWWu/sGM1sKdLj7CuAe4DvhZvouorAhjLuf6MZ8P/CH7j6QtKZUDfTDm+uhdz9c8qfw2E/BsnDCSZWuTERkQkjlHom7rwRWFrXdFpt+G/jYMMt+FfhqGnWUxdr/GYVI6ylw1Vfhf82vdEUiIhOKvtl+LNs2wON/HYXItDmVrkZEZEKqmk9tjTt3+NF/g6YTof1dla5GRGTC0hnJcF5/HLb8O3z4C5BtqHQ1IiITloJkOE98CyZNhfP/c6UrERGZ0BQkpezfBp0r4cJF0DCp0tWIiExoCpJSOldGjxI57zcrXYmIyISnICnl5R9B+2w4+T2VrkREZMJTkBTr3Q+v/gT+w6+O/rk3IiJ1SEFS7NWfwcAROOfqSlciIlIVFCTFup+KHvc+48JKVyIiUhUUJMW6O+DU9+nTWiIiI6QgicsPQM8zMPP9la5ERKRqKEjitr8EfQcVJCIio6AgieteF73r/oiIyIgpSOK2/hyaJ8PUMytdiYhI1VCQxL3VCdPfo++PiIiMgoIkbkcnTD+70lWIiFQVBUnBwZ1waCdMO6fSlYiIVBUFScGOzuh9uoJERGQ0FCQFOzZG7/qTuiIio6IgKdizBSwLJ86sdCUiIlVFQVKwZwtMngFZ/Rl7EZHRUJAU7NkCU06vdBUiIlVHQVKwZwtMeXelqxARqToKEoD+I7B/K0yeVelKRESqjoIEYF834DojEREZAwUJRJe1QEEiIjIGiYLEzKaa2Woz2xje24cZtyiM2Whmi2Lta82s08yeC6+Tk9QzZnu7o/fJ+uiviMhoJT0jWQKscfc5wJowP4SZTQW+BHwAuAj4UlHg3Oju54fX9oT1jM2BbdF76ykV2byISDVLGiQLgXvD9L3AR0uMuQpY7e673H03sBpYkHC76TqwHZpOhMaWSlciIlJ1kgbJKe6+NUy/CZT6lX4G8EZsvju0FfxduKz1RbMKPb/9wDZorcxVNRGRanfcr3Gb2SPAqSW6bo3PuLubmY9y+ze6e4+ZtQEPAr8N/P0wdSwGFgM0NTWNcjPHcWC7LmuJiIzRcYPE3S8frs/MtpnZae6+1cxOA0rd4+gB5sfmZwJrw7p7wvt+M/su0T2UkkHi7suAZQBtbW2jDaxjO7ANTj0v1VWKiNSLpJe2VgCFT2EtAn5YYswq4Eozaw832a8EVplZzsymAZhZA/AR4IWE9YzN/m3QWuqkS0REjidpkNwOXGFmG4HLwzxmNs/Mvg3g7ruArwDrwmtpaGsiCpT1wHNEZy5/m7Ce0TtyEI7s1z0SEZExSvSoW3ffCVxWor0D+FRsfjmwvGjMQeDCJNtPxYFwNU73SERExkTfbFeQiIgkoiA5+mXE6ZWtQ0SkSilIDu+K3ltOqmwdIiJVSkFyeHf0PqnkY8JEROQ4FCSHdkG2CRr0eBQRkbFQkBzeHZ2NVOjpLCIi1U5BUggSEREZEwXJ4d3QMrXSVYiIVC0Fic5IREQSUZAc3g2TplS6ChGRqlXfQeIefWprki5tiYiMVX0HSd9hGOjVpS0RkQTqO0j0ZUQRkcTqPEgKj0fRpS0RkbGq8yDRGYmISFJ1HiR7ovfmyRUtQ0SkmtV3kPTuj96bTqxsHSIiVUxBAgoSEZEE6jtIjhSCpLWydYiIVLH6DpLe/dEj5HNNla5ERKRqKUia2ipdhYhIVVOQKEhERBJRkChIREQSUZDoE1siIonUeZDs0xmJiEhCdR4kurQlIpKUgkRBIiKSiIJEQSIikkiiIDGzqWa22sw2hveSj9E1s381sz1m9lBR+2wze9LMuszs+2bWmKSeUenvhYEjChIRkYSSnpEsAda4+xxgTZgv5WvAb5dovwP4S3c/C9gN3JSwnpHTc7ZERFKRNEgWAveG6XuBj5Ya5O5rgP3xNjMz4MPAA8dbvix690Xves6WiEgiuYTLn+LuW8P0m8Apo1j2JGCPu/eH+W5gxnCDzWwxsDjM9prZC6MttqQv3wjcOKKhUfa9c/pYfSMdl8A0YEcaK6oB2heDtC8GaV8MOqccKz1ukJjZI8CpJbpujc+4u5uZp1VYMXdfBiwLNXW4+7xybauaaF8M0r4YpH0xSPtikJl1lGO9xw0Sd798uD4z22Zmp7n7VjM7Ddg+im3vBKaYWS6clcwEekaxvIiITABJ75GsABaF6UXAD0e6oLs78Bhw3ViWFxGRiSFpkNwOXGFmG4HLwzxmNs/Mvl0YZGY/A/4RuMzMus3sqtD1p8DnzKyL6J7JPSPc7rKEddcS7YtB2heDtC8GaV8MKsu+sOjEQEREZGzq+5vtIiKSmIJEREQSqaogMbMFZtYZHqky3Lfoq5qZzTKzx8zsRTPbYGafDe0lH0djkW+EfbLezC6IrWtRGL/RzBYNt82JzsyyZvZs4RE7wz1ax8yawnxX6D8jto5bQntn7B5dVTGzKWb2gJm9bGYvmdkl9XpcmNkfh38fL5jZ98ysuV6OCzNbbmbb49+lS/M4MLMLzez5sMw3zEbwhTd3r4oXkAU2AWcCjcDPgXMrXVcZfs7TgAvCdBvwCnAu8L+BJaF9CXBHmL4GeBgw4GLgydA+Fdgc3tvDdHulf74x7pPPAd8FHgrz9wPXh+m7gE+H6f8C3BWmrwe+H6bPDcdLEzA7HEfZSv9cY9gP9wKfCtONwJR6PC6Ivrj8KjApdjx8sl6OC+BS4ALghVhbascB8FQYa2HZq49bU6V3yih23iXAqtj8LcAtla5rHH7uHwJXAJ3AaaHtNKAzTN8N3BAb3xn6bwDujrUPGVctL6LvF60hepzOQ+Hg3gHkio8LYBVwSZjOhXFWfKzEx1XLC5gc/udpRe11d1yEIHkj/E8wF46Lq+rpuADOKAqSVI6D0PdyrH3IuOFe1XRpq3DwFBzzkSq1IJyCzwWeZPjH0Qy3X2plf/0V8N+BfJg/1qN1jv7MoX9vGF8L+2I28Bbwd+Ey37fN7ATq8Lhw9x7gL4AtwFai/85PU5/HRUFax8GMMF3cfkzVFCR1xcxagQeB/+ru++J9Hv2qUPOf2zazjwDb3f3pStcyAeSILmd8y93nAgcpetp2HR0X7UQPjJ0NvAs4AVhQ0aImkEocB9UUJD3ArNh8zT5SxcwaiELkH9z9B6F5m0WPocGGPo5muP1SC/vrg8C1ZvYacB/R5a2/JjxaJ4yJ/1xHf+bQP5noUTy1sC+6gW53fzLMP0AULPV4XFwOvOrub7l7H/ADomOlHo+LgrSOg54wXdx+TNUUJOuAOeGTGY1EN81WVLim1IVPSNwDvOTuX491Dfc4mhXAJ8KnMy4G9oZT3FXAlWbWHn6DuzK0VQ13v8XdZ7r7GUT/vR919xsZ/tE68X10XRjvof368Omd2cAcohuKVcPd3wTeMLPC01svA16kDo8LoktaF5tZS/j3UtgXdXdcxKRyHIS+fWZ2cdi3n2Akj66q9E2jUd5guoboU0ybgFsrXU+Zfsb/RHRauh54LryuIbqmuwbYCDwCTA3jDbgz7JPngXmxdf0u0BVev1Ppny3hfpnP4Ke2ziT6B99F9OidptDeHOa7Qv+ZseVvDfuokxF8CmUivoDzgY5wbPwz0adt6vK4AL4MvAy8AHyH6JNXdXFcAN8jujfUR3SmelOaxwEwL+zXTcA3KfqAR6mXHpEiIiKJVNOlLRERmYAUJCIikoiCREREElGQiIhIIgoSERFJREEiIiKJKEhERCSR/w847oABMGDukwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 873, 974, 1075, 1176, 1277, 1378, 1479]\n"
          ]
        }
      ]
    }
  ]
}